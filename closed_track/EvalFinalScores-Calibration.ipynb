{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3123a444-c8b9-4aa3-a164-ae10f436fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Union, Any\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b5d1ed-3086-411d-ae90-213aac96260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the thresholds computed from the ThresholdTuning_calibration.ipynb on the dev set.\n",
    "# Applies the new thresholds to the logits on the eval data.\n",
    "# Computes overall score by averaging for all 4 parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "056666ca-72fa-40f0-8583-dd6453189315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corn_forward_logits(raw_logits: torch.Tensor):\n",
    "    B, K1 = raw_logits.shape\n",
    "    shifted_logits = torch.zeros_like(raw_logits)\n",
    "    shifted_logits[:, 0] = raw_logits[:, 0]\n",
    "    for k in range(1, K1):\n",
    "        log_odds_prev = shifted_logits[:, k-1]\n",
    "        shifted_logits[:, k] = raw_logits[:, k] + log_odds_prev\n",
    "    return shifted_logits\n",
    "\n",
    "def corn_inference(raw_logits: torch.Tensor, dict_fixedThresholds):\n",
    "    \"\"\"\n",
    "    raw_logits: shape (B, K-1)\n",
    "    Return integer predictions in [0..K].\n",
    "    We'll do the same shifting, then threshold each probability at 0.5.\n",
    "    \"\"\"\n",
    "    z = corn_forward_logits(raw_logits)  # shift\n",
    "    p = torch.sigmoid(z)\n",
    "    \n",
    "    threshold_list = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
    "    for key in dict_fixedThresholds.keys():\n",
    "        threshold_list[key] = dict_fixedThresholds[key]\n",
    "       \n",
    "    threshold_tensor = torch.tensor(threshold_list)\n",
    "    \n",
    "    pass_mask = raw_logits > threshold_tensor\n",
    "                \n",
    "    preds = pass_mask.sum(dim=1)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21a3d2a3-4711-4162-85e9-7e85d0f3d0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1_dict: {6: 0.02, 5: 0.52, 4: 0.55, 3: 0.75, 2: 0.9, 1: 0.62, 0: 0.7}\n",
      "p3_dict: {6: 0.05, 5: 0.55, 4: 0.62, 3: 0.88, 2: 0.7, 1: 0.62, 0: 0.8}\n",
      "p4_dict: {6: 0.38, 5: 0.2, 4: 0.3, 3: 0.32, 2: 0.4, 1: 0.85, 0: 0.8}\n",
      "p5_dict: {6: 0.48, 5: 0.1, 4: 0.38, 3: 0.68, 2: 0.78, 1: 0.88, 0: 0.98}\n"
     ]
    }
   ],
   "source": [
    "# Load CSV into DataFrame\n",
    "df = pd.read_csv(\"/m/triton/work/porwala1/slate_models/CornLoss_TrainDataModel_EvalPreds_withProbs/final_locked_thresholds_025.csv\")\n",
    "df[\"score\"] = (df[\"score\"] * 2 - 5).astype(int)\n",
    "\n",
    "# Create dictionaries for each threshold column\n",
    "dict_Thresholds_p1 = dict(zip(df[\"score\"], df[\"p1_threshold\"]))\n",
    "dict_Thresholds_p3 = dict(zip(df[\"score\"], df[\"p3_threshold\"]))\n",
    "dict_Thresholds_p4 = dict(zip(df[\"score\"], df[\"p4_threshold\"]))\n",
    "dict_Thresholds_p5 = dict(zip(df[\"score\"], df[\"p5_threshold\"]))\n",
    "\n",
    "# Print dictionaries\n",
    "print(\"p1_dict:\", dict_Thresholds_p1)\n",
    "print(\"p3_dict:\", dict_Thresholds_p3)\n",
    "print(\"p4_dict:\", dict_Thresholds_p4)\n",
    "print(\"p5_dict:\", dict_Thresholds_p5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdab670d-bad6-49f3-97e3-406c61182116",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/m/triton/work/porwala1/slate_models/CornLoss_TrainDataModel_EvalPreds_withProbs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9c5c71a-effd-4f74-b51e-1f8748bbf22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "P1_csv = pd.read_csv(path + \"/eval-preds-P1-withProb.csv\") #Get from CSV\n",
    "subIDs = P1_csv[\"submissionID\"].to_list()\n",
    "pred_logits_1_df = P1_csv.drop(columns=['score', 'submissionID'])\n",
    "pred_logits_1 = pred_logits_1_df.to_numpy()\n",
    "logits_t_1 = torch.from_numpy(pred_logits_1)\n",
    "\n",
    "preds_t_1 = corn_inference(logits_t_1, dict_Thresholds_p1)\n",
    "final_preds_1 = preds_t_1.cpu().numpy()\n",
    "final_preds_rescaled_1 = final_preds_1/2 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc6c8730-3c7c-44ff-86fa-95c3c4ed1214",
   "metadata": {},
   "outputs": [],
   "source": [
    "P3_csv = pd.read_csv(path + \"/eval-preds-P3-withProb.csv\") #Get from CSV\n",
    "pred_logits_3_df = P3_csv.drop(columns=['score', 'submissionID'])\n",
    "pred_logits_3 = pred_logits_3_df.to_numpy()\n",
    "logits_t_3 = torch.from_numpy(pred_logits_3)\n",
    "\n",
    "preds_t_3 = corn_inference(logits_t_3, dict_Thresholds_p3)\n",
    "final_preds_3 = preds_t_3.cpu().numpy()\n",
    "final_preds_rescaled_3 = final_preds_3/2 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9c61b37-e50d-4965-925b-c29757e1baf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "P4_csv = pd.read_csv(path + \"/eval-preds-P4-withProb.csv\") #Get from CSV\n",
    "pred_logits_4_df = P4_csv.drop(columns=['score', 'submissionID'])\n",
    "pred_logits_4 = pred_logits_4_df.to_numpy()\n",
    "logits_t_4 = torch.from_numpy(pred_logits_4)\n",
    "\n",
    "preds_t_4 = corn_inference(logits_t_4, dict_Thresholds_p4)\n",
    "final_preds_4 = preds_t_4.cpu().numpy()\n",
    "final_preds_rescaled_4 = final_preds_4/2 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aca7845-fda0-42ad-9b3d-12aa37c075e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "P5_csv = pd.read_csv(path + \"/eval-preds-P5-withProb.csv\") #Get from CSV\n",
    "pred_logits_5_df = P5_csv.drop(columns=['score', 'submissionID'])\n",
    "pred_logits_5 = pred_logits_5_df.to_numpy()\n",
    "logits_t_5 = torch.from_numpy(pred_logits_5)\n",
    "\n",
    "preds_t_5 = corn_inference(logits_t_5, dict_Thresholds_p5)\n",
    "final_preds_5 = preds_t_5.cpu().numpy()\n",
    "final_preds_rescaled_5 = final_preds_5/2 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0eb5703-a78a-4b65-b579-62762f24ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "predOverallScore = np.mean([final_preds_rescaled_1, final_preds_rescaled_3, final_preds_rescaled_4, final_preds_rescaled_5], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2e0ec4e-d9f8-4fd6-ad00-b41d7492aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"subID\": subIDs, \"score\": predOverallScore})\n",
    "df.to_csv(path + \"/sla.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python generic (scicomp-python-env/2024-01)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
